{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle OpenStreetMap Data\n",
    "## 1. Chosen Area\n",
    "I'm going to wrangle on the coast of Pernambuco, Brazil openstreetmap data. In this area alone lives roghly 5 million people. It also has some of the most beautiful Brazilian beaches and it is also where I live :).\n",
    "\n",
    "## 2. Objective \n",
    "The objective here is to work with streets only fixing their prefixes and postal codes. In Portuguese the streets types such as Street, Avenue, etc comes first and not last as in Engligh so that a street called Silva Street in English is Rua Silva in Portuguese.<br>\n",
    "A secondary objective is to find what and where other issues at this dataset are and give some options on how those issues could be fixed and the dataset quality improved.\n",
    "\n",
    "## 3. Wrangling\n",
    "### 3.1. OSM File\n",
    "The first step was to select the area and download its osm file from the openstreetmap website. I named the file **PE_Coast.osm** and has around 100MB.<br>\n",
    "-rw-r--r--@  1 leo  staff  98919948 Sep 10 10:35 PE_Coast.osm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OSM_FILE_FULL = \"PE_Coast.osm\"  # Full OSM File\n",
    "OSM_FILE_SAMPLE = \"PE_Coast_sample.osm\"  # Full OSM File\n",
    "OSM_FILE = OSM_FILE_FULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Wrangling Process\n",
    "#### 3.3.1 Tags Counting\n",
    "Started by counting the tags to get a sense of how many **way** tags we have in the file.<br>\n",
    "**'way': 66137**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'int'>, {'node': 430343, 'member': 10359, 'nd': 546941, 'tag': 175116, 'bounds': 1, 'note': 1, 'meta': 1, 'relation': 760, 'way': 66137, 'osm': 1})\n"
     ]
    }
   ],
   "source": [
    "# counting tags to get a sense of how many of each tags we have\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "\n",
    "def count_tags(filename):\n",
    "    tags = defaultdict(int)\n",
    "    for event, elem in ET.iterparse(filename):\n",
    "        tags[elem.tag] += 1\n",
    "    \n",
    "    return tags\n",
    "\n",
    "tags = count_tags(OSM_FILE)\n",
    "pprint.pprint(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Street Types Counts\n",
    "To get a sense of how many different street types and their counts I'll count and print all different street types below (prefixes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Rua', 13322),\n",
      " ('Avenida', 1479),\n",
      " ('Travessa', 431),\n",
      " ('Estrada', 225),\n",
      " (u'Pra\\xe7a', 127),\n",
      " ('Rodovia', 97),\n",
      " (u'Acesso', 60),\n",
      " ('Ponte', 59),\n",
      " (u'1\\xaa', 35),\n",
      " ('Alameda', 34)]\n"
     ]
    }
   ],
   "source": [
    "# In Brazil the street type comes first (Avenue, Street, etc)\n",
    "# This snippet checks all the street names prefixes in teh OSM file to see if there's anything strange or not expected as the street type\n",
    "# The definition of street is: it's a way tag with a tag with k equals to highway\n",
    "\n",
    "def check_street_types_counts():\n",
    "    street_types_counts = defaultdict(int)\n",
    "    for _, element in ET.iterparse(OSM_FILE):\n",
    "        if element.tag == \"way\":\n",
    "            is_street = False\n",
    "            street_name = None\n",
    "            for tag in element.iter(\"tag\"):\n",
    "                if tag.get(\"k\") == \"highway\":\n",
    "                    is_street = True\n",
    "                elif tag.get(\"k\") == \"name\":\n",
    "                    street_name = tag.get(\"v\")\n",
    "#                     print street_name\n",
    "            if is_street and street_name is not None:\n",
    "                street_type = street_name.split(\" \")[0]\n",
    "#                 print street_type\n",
    "                street_types_counts[street_type] += 1\n",
    "\n",
    "    return street_types_counts\n",
    "\n",
    "street_types_counts = check_street_types_counts()\n",
    "#pprint.pprint(dict(street_types_counts))\n",
    "\n",
    "# print the street_types_counts dictionary, only sorted by count\n",
    "sorted_dict = sorted(street_types_counts.items(), key=lambda x:x[1], reverse = True)\n",
    "\n",
    "# print the first 10 entries\n",
    "pprint.pprint(sorted_dict[0:10])\n",
    "\n",
    "# in case you want to print all street types\n",
    "#pprint.pprint(sorted_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3 Street Types Counts Ordered\n",
    "I'll order the list above by the counts so we can see what are the most important street prefixes to tackle.<br>\n",
    "To help non-Portugues speakers I'll translate some of the names found below:<br>\n",
    "Rua - Street<br>\n",
    "Avenida - Avenue<br>\n",
    "Estrada - Road<br>\n",
    "Praça - Park<br>\n",
    "Ponte - Bridge<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.5 Getting Way Ids To Manually Check Some Entries\n",
    "I found some of the prefixes in the list above a bit strange so I decided to check some of them directly in the file. For that I need the respective way ids related to each street name I want to manually check. <br>\n",
    "Example: for the first item inthe list printed below we have:<br>\n",
    "'1': set(['141891164', '141891277']<br>\n",
    "That means that ways **141891164** and **141891277** have street names that start with **1**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'8\\xaa', set(['244905531'])),\n",
      " (u'Canal', set(['141889672', '166190857', '172251206'])),\n",
      " (u'Sa\\xedda',\n",
      "  set(['131641926',\n",
      "       '131641927',\n",
      "       '131641928',\n",
      "       '131641930',\n",
      "       '134470862',\n",
      "       '134470866',\n",
      "       '434363071',\n",
      "       '434363081'])),\n",
      " ('Parque', set(['155451779'])),\n",
      " ('rUA', set(['427830380']))]\n"
     ]
    }
   ],
   "source": [
    "# map the street prefixes with the respective way ids\n",
    "# used to manually check some odd results I found at first glance\n",
    "\n",
    "def check_street_types_way_id():\n",
    "    street_types_ways = defaultdict(set)\n",
    "    for _, element in ET.iterparse(OSM_FILE):\n",
    "        if element.tag == \"way\":\n",
    "            way_id = element.get(\"id\")\n",
    "            is_street = False\n",
    "            street_name = None\n",
    "            for tag in element.iter(\"tag\"):\n",
    "                if tag.get(\"k\") == \"highway\":\n",
    "                    is_street = True\n",
    "                elif tag.get(\"k\") == \"name\":\n",
    "                    street_name = tag.get(\"v\")\n",
    "            if is_street:\n",
    "                if None == street_name:\n",
    "                    street_types_ways[\"None\"].add(way_id)\n",
    "                else:\n",
    "                    street_type = street_name.split(\" \")[0]\n",
    "                    street_types_ways[street_type].add(way_id)\n",
    "    return street_types_ways\n",
    "\n",
    "street_types_ways = dict(check_street_types_way_id())\n",
    "\n",
    "# print the first 5 entries\n",
    "pprint.pprint(street_types_ways.items()[0:5])\n",
    "\n",
    "# in case you want to print all street_types_ways\n",
    "#pprint.pprint(street_types_ways)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.6 Looking For Bad Postal Codes In Streets Entries\n",
    "Below I'll check if the postal_code tag value are valid for all streets. I'll print the bad ones to decide how to fix them later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5473550 - Rua Treze de Maio\n",
      "0970-120 - Rua Tenente Roland Rittmíster\n",
      "5475675 - Rua Pedro Carlos do Nascimento\n",
      "0970-120 - Rua Tenente Roland Rittmíster\n"
     ]
    }
   ],
   "source": [
    "# postal codes in Brazil are in the format 12345-123\n",
    "# below I'll check if the postal_codes fields in the streets are in this format\n",
    "# I'll print only the ones that doesn't match this format so I can decide what to do to fix them later\n",
    "import re\n",
    "postal_code_pattern = '\\d{5}-\\d{3}'\n",
    "postal_code_pattern_compiled = re.compile(postal_code_pattern)\n",
    "\n",
    "def check_postal_codes():\n",
    "    for _, element in ET.iterparse(OSM_FILE):\n",
    "        if element.tag == \"way\":\n",
    "            way_id = element.get(\"id\")\n",
    "            is_street = False\n",
    "            postal_code = None\n",
    "            street_name = None\n",
    "            for tag in element.iter(\"tag\"):\n",
    "                if tag.get(\"k\") == \"highway\":\n",
    "                    is_street = True\n",
    "                elif tag.get(\"k\") == \"postal_code\":\n",
    "                    postal_code = tag.get(\"v\")\n",
    "                elif tag.get(\"k\") == \"name\":\n",
    "                    street_name = tag.get(\"v\")\n",
    "            if is_street and None != postal_code and not postal_code_pattern_compiled.match(postal_code):\n",
    "                print postal_code + \" - \" + street_name\n",
    "\n",
    "check_postal_codes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.7 Creating the Replacement Dictionaries\n",
    "After manually checking some of the entries that I found odd using the dictionary above I now can create the dictionary below that simple maps the bad or wrong street name prefixes found in the file with the right ones. <br>\n",
    "For the postal codes, since it's just 4 bad entries, I've manually searched for the postal codes in google maps and created the postal code replacement map below. If we had more bad entries an automated way of doing this would be the way to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replacement dictionary to be used to clean up the street prefixes\n",
    "# this dictionary had been built by analyzing the information from the data mungling steps above\n",
    "prefix_replacement_map = {\"travessa\": \"Travessa\",\n",
    "\"Travesa\": \"Travessa\",\n",
    "\"Av.\": \"Avenida \",\n",
    "\"Av\": \"Avenida \",\n",
    "\"R.\": \"Rua\",\n",
    "\"rua\": \"Rua\",\n",
    "\"Ria\": \"Rua\",\n",
    "\"rUA\": \"Rua\",\n",
    "\"segunda\": \"2a\",\n",
    "\"Terceira\": \"3a\",\n",
    "\"Quarta\": \"4a\",\n",
    "u'1\\xb0': \"1a\",\n",
    "u'2\\xb0': \"2a\",\n",
    "u'3\\xb0': \"3a\",\n",
    "u'4\\xb0': \"4a\",\n",
    "u'5\\xb0': \"5a\",\n",
    "u'6\\xb0': \"6a\",\n",
    "u'7\\xb0': \"7a\",\n",
    "u'8\\xb0': \"8a\",\n",
    "u\"1\\xaa\": \"1a\",\n",
    "u\"2\\xaa\": \"2a\",\n",
    "u\"3\\xaa\": \"3a\",\n",
    "u\"4\\xaa\": \"4a\",\n",
    "u\"5\\xaa\": \"5a\",\n",
    "u\"6\\xaa\": \"6a\",\n",
    "u\"7\\xaa\": \"7a\",\n",
    "u\"8\\xaa\": \"8a\",\n",
    "\"1\": \"1a\",\n",
    "\"2\": \"2a\",\n",
    "\"3\": \"3a\",\n",
    "\"4\": \"4a\",\n",
    "\"5\": \"5a\",\n",
    "\"6\": \"6a\",\n",
    "\"7\": \"7a\",\n",
    "\"8\": \"8a\",\n",
    "\"Primeira\": \"1a\",\n",
    "\"Segunda\": \"2a\",\n",
    "\"Terceira\": \"3a\",\n",
    "\"Quarta\": \"4a\"}\n",
    "\n",
    "# replacement dictionary to be used to clean up the bad postal codes\n",
    "postal_code_replacement_map = {\"5473550\": \"54735-500\",\n",
    "\"0970-120\": \"50970-120\",\n",
    "\"5475675\": \"54756-275\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.8 Applying the Replacement Dictionary\n",
    "Now it's time to use the dictionary to replace the bad prefixes. As I'm already looping through the entire file to read and fix the street prefixes I will use this opportunity to create the json file to be imported into mongdb int the next step.\n",
    "\n",
    "Note that I'm getting as much information as I find valuable to make further analysis such as the tags lit, surface, maxspeed and many others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### import codecs\n",
    "import json\n",
    "\n",
    "# replaces the bad string prefixes (street types)\n",
    "def replace_from_map(name, replacement_map):\n",
    "    for key in replacement_map:\n",
    "        if name.split(\" \")[0] == key:\n",
    "            name.replace(key, replacement_map[key], 1)\n",
    "            name = name.replace(key, replacement_map[key], 1)\n",
    "            break\n",
    "    return name\n",
    "\n",
    "# processes each element from the open street map xml file\n",
    "# returns a dictionary of this element\n",
    "def process_element(element):\n",
    "    way = {}\n",
    "    if element.tag == \"way\":\n",
    "        is_street = False\n",
    "        way[\"name\"] = None\n",
    "        way_element = element\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            if tag.get(\"k\") == \"highway\":\n",
    "                is_street = True\n",
    "                way[\"highway\"] = tag.get(\"v\")\n",
    "            elif tag.get(\"k\") == \"name\":\n",
    "                way[\"name\"] = tag.get(\"v\")\n",
    "            elif tag.get(\"k\") == \"oneway\":\n",
    "                way[\"oneway\"] = tag.get(\"v\")\n",
    "            elif tag.get(\"k\") == \"surface\":\n",
    "                way[\"surface\"] = tag.get(\"v\")\n",
    "            elif tag.get(\"k\") == \"lit\":\n",
    "                way[\"lit\"] = tag.get(\"v\")\n",
    "            elif tag.get(\"k\") == \"access\":\n",
    "                way[\"access\"] = tag.get(\"v\")\n",
    "            elif tag.get(\"k\") == \"emergency\":\n",
    "                way[\"emergency\"] = tag.get(\"v\")\n",
    "            elif tag.get(\"k\") == \"lanes\":\n",
    "                way[\"lanes\"] = int(tag.get(\"v\"))\n",
    "            elif tag.get(\"k\") == \"layer\":\n",
    "                way[\"layer\"] = int(tag.get(\"v\"))\n",
    "            elif tag.get(\"k\") == \"maxspeed\":\n",
    "                way[\"maxspeed\"] = int(tag.get(\"v\"))\n",
    "            elif tag.get(\"k\") == \"bridge\":\n",
    "                way[\"bridge\"] = tag.get(\"v\")\n",
    "            elif tag.get(\"k\") == \"noexit\":\n",
    "                way[\"noexit\"] = tag.get(\"v\")\n",
    "            elif tag.get(\"k\") == \"cycleway\" or tag.get(\"k\") == \"cycleway:right\" or tag.get(\"k\") == \"cycleway:left\":\n",
    "                way[\"cycleway\"] = tag.get(\"v\")\n",
    "            elif tag.get(\"k\") == \"sidewalk\":\n",
    "                way[\"sidewalk\"] = tag.get(\"v\")\n",
    "            elif tag.get(\"k\") == \"amenity\":\n",
    "                way[\"amenity\"] = tag.get(\"v\")\n",
    "            elif tag.get(\"k\") == \"postal_code\":\n",
    "                way[\"postal_code\"] = tag.get(\"v\")\n",
    "\n",
    "        if is_street:\n",
    "#             pprint.pprint(way[\"name\"])\n",
    "            if way[\"name\"] is not None:\n",
    "                way[\"name\"] = replace_from_map(way[\"name\"], prefix_replacement_map)\n",
    "            if \"postal_code\" in way:\n",
    "                way[\"postal_code\"] = replace_from_map(way[\"postal_code\"], postal_code_replacement_map)\n",
    "\n",
    "            way[\"id\"] = way_element.get(\"id\")\n",
    "            way[\"uid\"] = way_element.get(\"uid\")\n",
    "            way[\"user\"] = way_element.get(\"user\")\n",
    "            way[\"timestamp\"] = way_element.get(\"timestamp\")\n",
    "            way[\"version\"] = int(way_element.get(\"version\"))\n",
    "#             pprint.pprint(way[\"name\"])\n",
    "            return way \n",
    "        \n",
    "    return None\n",
    "\n",
    "# generates the json file to be imported into mongodb using the mongoimport command\n",
    "def process_file(file_in, pretty = False):\n",
    "    # You do not need to change this file\n",
    "    file_out = \"{0}_processed.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = process_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n",
    "    return data\n",
    "\n",
    "process_file(OSM_FILE, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.9 Importing the Generated JSON file in mongodb\n",
    "I need now to put this data I just fixed and generated into my local mongodb which is already running. I'll name the database **p3_leonardo**, the collection **osm** and run the command below (if you wnat to run it in your local machine just change the local path to the PE_Coast.osm_processed.json file):\n",
    "<br>\n",
    "mongoimport --db p3_leonardo --collection osm --file /Users/leo/Dropbox/udacity_nanodegree/P3/PE_Coast.osm_processed.json\n",
    "\n",
    "<output>\n",
    "Leonardos-Air:P3 leo$ mongoimport --db p3_leonardo --collection osm --file /Users/leo/Dropbox/udacity_nanodegree/P3/PE_Coast.osm_processed.json<br>\n",
    "2016-09-27T18:19:23.573-0300\tconnected to: localhost<br>\n",
    "2016-09-27T18:19:24.728-0300\timported 35330 documents\n",
    "\n",
    "#### 3.3.10 Reusable Functions\n",
    "The functions below will be reused later on when I use some mongodb aggregate functions to analyse the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_db(db_name):\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "\n",
    "def run_aggregation(pipeline):\n",
    "    db = get_db('p3_leonardo')\n",
    "    result = db.osm.aggregate(pipeline)\n",
    "    for r in result:\n",
    "        pprint.pprint(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.11 Checking if the street prefix and postal code replacement worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all prefixes and postal codes are good in the database!!\n"
     ]
    }
   ],
   "source": [
    "# Checking if the street prefix and postal code replacement worked\n",
    "db = get_db('p3_leonardo')\n",
    "\n",
    "everything_ok = True\n",
    "for key in prefix_replacement_map:\n",
    "    from_db = db.osm.find_one({\"name\": {\"$regex\": \"^\" + key + \" \"}})\n",
    "    if from_db != None:\n",
    "        print \"a bad street prefix in the database: \" + key\n",
    "        pprint.pprint(from_db)\n",
    "        print \"check the prefix replacement code\"\n",
    "        everything_ok = False\n",
    "        break\n",
    "    \n",
    "for key in postal_code_replacement_map:\n",
    "    from_db = db.osm.find_one({\"name\": {\"$regex\": \"^\" + key + \" \"}})\n",
    "    if from_db != None:\n",
    "        print \"a bad postal code in the database: \" + key\n",
    "        pprint.pprint(from_db)\n",
    "        print \"check the prefix replacement code\"       \n",
    "        everything_ok = False\n",
    "        break\n",
    "\n",
    "if everything_ok:\n",
    "    print \"all prefixes and postal codes are good in the database!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.12 Find the top 10 contributors\n",
    "TrvrHldr was the top contrinutor to the streets in this are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': u'TrvrHldr', u'count': 5552}\n",
      "{u'_id': u'patodiez', u'count': 5415}\n",
      "{u'_id': u'Usu\\xe1rioPar', u'count': 4356}\n",
      "{u'_id': u'erickdeoliveiraleal', u'count': 2943}\n",
      "{u'_id': u'plguedes', u'count': 2048}\n",
      "{u'_id': u'raphaelmirc', u'count': 1938}\n",
      "{u'_id': u'elias lopes', u'count': 1881}\n",
      "{u'_id': u'dbusse', u'count': 1153}\n",
      "{u'_id': u'Skippern', u'count': 1097}\n",
      "{u'_id': u'maiafelipe', u'count': 957}\n"
     ]
    }
   ],
   "source": [
    "# find the top 10 contributors to this area\n",
    "pipeline = [\n",
    "            {\"$group\" : {\"_id\" : \"$user\", \"count\" : {\"$sum\" : 1}}},\n",
    "            {\"$sort\" : {\"count\" : -1}},\n",
    "            {\"$limit\" : 10}\n",
    "            ]\n",
    "\n",
    "run_aggregation(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.13 Find the percentage of each street type\n",
    "We can see here that residential counts for ~72% of all streets while unclassified is only ~7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': u'residential', u'count': 25564, u'percentage': 72.35776960090574}\n",
      "{u'_id': u'unclassified', u'count': 2371, u'percentage': 6.711010472686102}\n",
      "{u'_id': u'secondary', u'count': 1111, u'percentage': 3.144636286442117}\n",
      "{u'_id': u'tertiary', u'count': 1034, u'percentage': 2.9266911972827625}\n",
      "{u'_id': u'primary', u'count': 965, u'percentage': 2.7313897537503538}\n",
      "{u'_id': u'service', u'count': 798, u'percentage': 2.258703651287857}\n",
      "{u'_id': u'footway', u'count': 766, u'percentage': 2.1681290687800736}\n",
      "{u'_id': u'pedestrian', u'count': 414, u'percentage': 1.1718086611944523}\n",
      "{u'_id': u'motorway', u'count': 381, u'percentage': 1.0784036229833003}\n",
      "{u'_id': u'track', u'count': 364, u'percentage': 1.03028587602604}\n",
      "{u'_id': u'primary_link', u'count': 321, u'percentage': 0.9085762807812057}\n",
      "{u'_id': u'motorway_link', u'count': 254, u'percentage': 0.7189357486555334}\n",
      "{u'_id': u'secondary_link', u'count': 226, u'percentage': 0.6396829889612227}\n",
      "{u'_id': u'trunk', u'count': 175, u'percentage': 0.49532974808944236}\n",
      "{u'_id': u'tertiary_link', u'count': 126, u'percentage': 0.3566374186243985}\n",
      "{u'_id': u'steps', u'count': 111, u'percentage': 0.31418058307387486}\n",
      "{u'_id': u'trunk_link', u'count': 87, u'percentage': 0.24624964619303705}\n",
      "{u'_id': u'path', u'count': 84, u'percentage': 0.23775827908293234}\n",
      "{u'_id': u'living_street', u'count': 67, u'percentage': 0.18964053212567222}\n",
      "{u'_id': u'bridleway', u'count': 48, u'percentage': 0.13586187376167563}\n",
      "{u'_id': u'road', u'count': 42, u'percentage': 0.11887913954146617}\n",
      "{u'_id': u'cycleway', u'count': 17, u'percentage': 0.048117746957260114}\n",
      "{u'_id': u'raceway', u'count': 4, u'percentage': 0.011321822813472968}\n"
     ]
    }
   ],
   "source": [
    "# find the percentage of each street type\n",
    "db = get_db('p3_leonardo')\n",
    "total_street_count = db.osm.count()\n",
    "pipeline = [\n",
    "            {\"$group\" : {\"_id\" : \"$highway\", \"count\" : {\"$sum\" : 1}}},\n",
    "            {\"$sort\" : {\"count\" : -1}},\n",
    "            {\"$project\" : {\"count\" : 1, \"percentage\" : {\"$multiply\" : [{\"$divide\" : [100, total_street_count]}, \"$count\"]}}}\n",
    "            ]\n",
    "\n",
    "run_aggregation(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.14 Find the top contributors to the streets in the db in the last 30 days\n",
    "UsuárioPar was the top contributor in the last 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': u'Usu\\xe1rioPar', u'count': 1553}\n",
      "{u'_id': u'Alexandre Rui Barboza Lima', u'count': 88}\n",
      "{u'_id': u'ThiagoPv', u'count': 36}\n",
      "{u'_id': u'CupBlack', u'count': 11}\n",
      "{u'_id': u'xamico', u'count': 9}\n",
      "{u'_id': u'Villenom', u'count': 1}\n",
      "{u'_id': u'maiafelipe', u'count': 1}\n"
     ]
    }
   ],
   "source": [
    "# find the top contributors to the streets in the db in the last 30 days\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "# first convert the timestamp field from string to datetime in the db\n",
    "all_streets = db.osm.find()\n",
    "for street in all_streets:\n",
    "#     pprint.pprint(street)\n",
    "    try:\n",
    "        date_object = datetime.strptime(street[\"timestamp\"], '%Y-%m-%dT%H:%M:%SZ')\n",
    "        db.osm.update_one({\"_id\" : street[\"_id\"]}, {\"$set\" : {\"timestamp\" : date_object}})\n",
    "    except TypeError:\n",
    "        # db already updated\n",
    "        pass\n",
    "\n",
    "thirty_days_ago = datetime.now() + timedelta(days=-30)\n",
    "        \n",
    "pipeline = [\n",
    "            {\"$match\" : {\"timestamp\": {\"$gte\": thirty_days_ago}}},\n",
    "            {\"$group\" : {\"_id\" : \"$user\", \"count\" : {\"$sum\" : 1}}},\n",
    "            {\"$sort\" : {\"count\" : -1}}\n",
    "            ]\n",
    "\n",
    "run_aggregation(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.15 Find the percentage of the streeets that doesn't have lit information\n",
    "~90% of the entries doesn't have information about whether of or not the streets are lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': None, u'count': 31981, u'percentage': 90.52080384941975}\n",
      "{u'_id': u'yes', u'count': 3235, u'percentage': 9.156524200396262}\n",
      "{u'_id': u'no', u'count': 114, u'percentage': 0.3226719501839796}\n"
     ]
    }
   ],
   "source": [
    "# find the percentage of the streeets that doesn't have lit information\n",
    "\n",
    "pipeline = [\n",
    "            {\"$group\" : {\"_id\" : \"$lit\", \"count\" : {\"$sum\" : 1}}},\n",
    "            {\"$sort\" : {\"count\" : -1}},\n",
    "            {\"$project\" : {\"count\" : 1, \"percentage\" : {\"$multiply\" : [{\"$divide\" : [100, total_street_count]}, \"$count\"]}}}\n",
    "            ]\n",
    "\n",
    "run_aggregation(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.16 Find the percentage of the streeets that doesn't have surface information\n",
    "~86% of the entries doesn't have information about its surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': None, u'count': 30489, u'percentage': 86.29776393999433}\n",
      "{u'_id': u'paved', u'count': 2558, u'percentage': 7.240305689215964}\n",
      "{u'_id': u'unpaved', u'count': 1018, u'percentage': 2.8814039060288703}\n",
      "{u'_id': u'asphalt', u'count': 914, u'percentage': 2.5870365128785733}\n",
      "{u'_id': u'paving_stones', u'count': 111, u'percentage': 0.31418058307387486}\n",
      "{u'_id': u'cobblestone', u'count': 109, u'percentage': 0.3085196716671384}\n",
      "{u'_id': u'dirt', u'count': 52, u'percentage': 0.1471836965751486}\n",
      "{u'_id': u'sand', u'count': 33, u'percentage': 0.093405038211152}\n",
      "{u'_id': u'concrete', u'count': 28, u'percentage': 0.07925275969431078}\n",
      "{u'_id': u'ground', u'count': 8, u'percentage': 0.022643645626945937}\n",
      "{u'_id': u'sett', u'count': 2, u'percentage': 0.005660911406736484}\n",
      "{u'_id': u'earth', u'count': 2, u'percentage': 0.005660911406736484}\n",
      "{u'_id': u'wood', u'count': 1, u'percentage': 0.002830455703368242}\n",
      "{u'_id': u'paved;asphalt', u'count': 1, u'percentage': 0.002830455703368242}\n",
      "{u'_id': u'unpaved;paved', u'count': 1, u'percentage': 0.002830455703368242}\n",
      "{u'_id': u'paving_stones;asphalt',\n",
      " u'count': 1,\n",
      " u'percentage': 0.002830455703368242}\n",
      "{u'_id': u'concrete:lanes', u'count': 1, u'percentage': 0.002830455703368242}\n",
      "{u'_id': u'dirty', u'count': 1, u'percentage': 0.002830455703368242}\n"
     ]
    }
   ],
   "source": [
    "# find the percentage of the streeets that doesn't have surface information\n",
    "\n",
    "pipeline = [\n",
    "            {\"$group\" : {\"_id\" : \"$surface\", \"count\" : {\"$sum\" : 1}}},\n",
    "            {\"$sort\" : {\"count\" : -1}},\n",
    "            {\"$project\" : {\"count\" : 1, \"percentage\" : {\"$multiply\" : [{\"$divide\" : [100, total_street_count]}, \"$count\"]}}}\n",
    "            ]\n",
    "\n",
    "run_aggregation(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.17 Find the percentage of the streeets that doesn't have oneway information\n",
    "~60% of the streets doesn't have information about the flow direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': None, u'count': 21215, u'percentage': 60.04811774695725}\n",
      "{u'_id': u'no', u'count': 9641, u'percentage': 27.288423436173222}\n",
      "{u'_id': u'yes', u'count': 4474, u'percentage': 12.663458816869515}\n"
     ]
    }
   ],
   "source": [
    "# find the percentage of the streeets that doesn't have oneway information\n",
    "\n",
    "pipeline = [\n",
    "            {\"$group\" : {\"_id\" : \"$oneway\", \"count\" : {\"$sum\" : 1}}},\n",
    "            {\"$sort\" : {\"count\" : -1}},\n",
    "            {\"$project\" : {\"count\" : 1, \"percentage\" : {\"$multiply\" : [{\"$divide\" : [100, total_street_count]}, \"$count\"]}}}\n",
    "            ]\n",
    "\n",
    "run_aggregation(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.18 Find the percentage of street without a name\n",
    "~53% of the streets doesn't have a name in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': None, u'count': 18867, u'percentage': 53.40220775544862}\n"
     ]
    }
   ],
   "source": [
    "# find the percentage of street without a name\n",
    "pipeline = [\n",
    "            {\"$match\" : {\"name\": None}},\n",
    "            {\"$group\" : {\"_id\" : \"$name\", \"count\" : {\"$sum\" : 1}}},\n",
    "            {\"$sort\" : {\"count\" : -1}},\n",
    "            {\"$project\" : {\"count\" : 1, \"percentage\" : {\"$multiply\" : [{\"$divide\" : [100, total_street_count]}, \"$count\"]}}}\n",
    "            ]\n",
    "\n",
    "run_aggregation(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusion\n",
    "The streets related data in this dataset has some obvious gaps like ~53% of the streets miss the name tag which makes it not much attractive for a serious use.\n",
    "### 4.1. Some Thoughts on How to Fill This Gap \n",
    "I'll list below some ideas on how we could improve this data.\n",
    "\n",
    "#### 4.1.1. Brazilian Data Agencies \n",
    "Through the wranging process I noticed that some streets has tags like this one.\n",
    "```xml\n",
    "<tag k=\"note:pt\" v=\"Sem nome no IBGE ou no mapa da Prefeitura do Recife em 17/02/2015\"/>\n",
    "```\n",
    "IBGE is the Brazilian Institute of Geography and Statistics<br>\n",
    "Prefeitura do Recife is the Recife City Hall<br>\n",
    "\n",
    "Data from other agencies such as National Departament of Roads, the State Departament of Roads, Cities agencies, National Postal Service and others could be mungled with he data that is already there.\n",
    "\n",
    "#### 4.1.2. Google Maps\n",
    "The Google Geolocation API could be used to fill this gap and more. It could be used as well as to confirm some of the existing data such as street names, postal codes, oneway data and others. This option would come with a cost, though. As of today the Google Geolocation API has a 2,500 requests free daily quota + $0.50 per 1000 excess requests (in U.S. dollars).\n",
    "\n",
    "#### 4.1.3. Final Notes\n",
    "I'm sure that the ideas proposed here are just a subset of what can be done to improve this dataset. Note that there's no magic bullet and even data used to fix this dataset can be wrong or damaged in someways. <br>\n",
    "The OpenStreetMap data biggest strenght is the community and maybe using the power of the community is the way to go. Maybe throwing online competitions and/or creating an app (kind of how Waze started out) to help improving the maps while driving would be a more obvious and general approach to this general and global issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://wiki.openstreetmap.org/wiki/OSM_XML<br>\n",
    "http://stackoverflow.com/questions/12925052/python-and-default-dict-how-to-pprint<br>\n",
    "http://stackoverflow.com/questions/613183/sort-a-python-dictionary-by-value?page=1&tab=votes#tab-top<br>\n",
    "http://stackoverflow.com/questions/16772071/sort-dict-by-value-python<br>\n",
    "http://stackoverflow.com/questions/2672326/what-does-a-leading-x-mean-in-a-python-string-xaa<br>\n",
    "http://wiki.openstreetmap.org/wiki/Highways<br>\n",
    "http://stackoverflow.com/questions/16471332/how-can-i-compare-a-unicode-type-to-a-string-in-python<br>\n",
    "http://wiki.openstreetmap.org/wiki/Key:lit<br>\n",
    "http://wiki.openstreetmap.org/wiki/Key:surface<br>\n",
    "http://stackoverflow.com/questions/31188966/get-percentages-with-mongodb-aggregate-group<br>\n",
    "http://stackoverflow.com/questions/2900674/how-do-i-convert-a-property-in-mongodb-from-text-to-date-type<br>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
